{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Example usage\n",
                "\n",
                "To use `nf_parser` in a project:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 159,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0.0.1\n"
                    ]
                }
            ],
            "source": [
                "import nf_parser\n",
                "\n",
                "print(nf_parser.__version__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pathlib import Path\n",
                "\n",
                "def get_sample(name:str='1.nf'):\n",
                "    txt = Path(f\"../tests/samples/{name}\").read_text()\n",
                "    return txt"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "start\n",
                        "  shebang\t#!/usr/bin/env nextflow\n",
                        "  comment\t/*\n",
                        " * Defines the pipeline input parameters (with a default value for each one).\n",
                        " * Each of the following parameters can be specified as command line options.\n",
                        " */\n",
                        "  param\n",
                        "    query\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "  param\n",
                        "    db\n",
                        "    string\t\"$baseDir/blast-db/pdb/tiny\"\n",
                        "  param\n",
                        "    out\n",
                        "    string\t\"result.txt\"\n",
                        "  param\n",
                        "    chunkSize\n",
                        "    int\t100\n",
                        "  expression\tdb_name = file(params.db).name\n",
                        "  expression\tdb_dir = file(params.db).parent\n",
                        "  dsl\t2\n",
                        "  module_import\n",
                        "    foo\n",
                        "    './module/1.nf'\n",
                        "  module_import\n",
                        "    BAR\n",
                        "    './module/2.nf'\n",
                        "  expression\tdb_name = file(params.db).name\n",
                        "  comment\t//def sayHello() {\n",
                        "  comment\t//    println \"$params.foo $params.bar\"\n",
                        "  comment\t//}\n",
                        "  channel\t\n",
                        "\n",
                        "Channel.fromPath(params.query)\n",
                        "  comment\t/*\n",
                        " * Defines the pipeline input parameters (with a default value for each one).\n",
                        " * Each of the following parameters can be specified as command line options.\n",
                        " */\n",
                        "  param\n",
                        "    in\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "    comment\t// path to fa file\n",
                        "  comment\t// some comment\n",
                        "  param\n",
                        "    query\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "  param\n",
                        "    db\n",
                        "    string\t\"$baseDir/blast-db/pdb/tiny\"\n",
                        "  param\n",
                        "    out\n",
                        "    string\t\"result.txt\"\n",
                        "  param\n",
                        "    chunkSize\n",
                        "    int\t100\n",
                        "  process\n",
                        "    foo\n",
                        "    process_block\n",
                        "      directive\n",
                        "        container\n",
                        "          string\t'python'\n",
                        "      output\n",
                        "        path\n",
                        "          string\t'sample.txt'\n",
                        "      script\n",
                        "        comment\t// script comment\n",
                        "        shell_script\t'''\n",
                        "    echo 'hello' >  sample.txt\n",
                        "    '''\n",
                        "  workflow\n",
                        "    workflow_block\n",
                        "      main\n",
                        "        expression\t \n",
                        "\n",
                        "    foo()\n",
                        "  workflow\n",
                        "    jimmy\n",
                        "    workflow_block\n",
                        "      main\n",
                        "        expression\t\n",
                        "    foo()\n",
                        "      main\n",
                        "        comment\t/*\n",
                        "     * Create a channel emitting the given query fasta file(s).\n",
                        "     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\n",
                        "     * Finally, assign the resulting channel to the variable 'ch_fasta'\n",
                        "     */\n",
                        "        channel\t\n",
                        "    Channel\n",
                        "        .fromPath(params.query)\n",
                        "        operator\t.splitFasta(by: params.chunkSize, file:true)\n",
                        "        operator\t.set { ch_fasta }\n",
                        "      main\n",
                        "        comment\t/*\n",
                        "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                        "     * and emit the resulting BLAST matches.\n",
                        "     */\n",
                        "        expression\tch_hits = blast(ch_fasta, db_dir)\n",
                        "      main\n",
                        "        comment\t// define a channel emitting three values\n",
                        "        channel\tsource = Channel.of( 'alpha', 'beta', 'delta' )\n",
                        "      main\n",
                        "        comment\t/*\n",
                        "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                        "     * and emit the resulting BLAST matches.\n",
                        "     */\n",
                        "        operator\tch_sequences\n",
                        "        .collectFile(name: params.out)\n",
                        "        operator\t.view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                        "        channel\t\n",
                        "    \n",
                        "    Channel\n",
                        "        .watchPath( '/path/*.fa' )\n",
                        "        operator\t.subscribe { println \"Fasta file: $it\" }\n",
                        "        channel\t\n",
                        "\n",
                        "    Channel\n",
                        "        .watchPath( '/path/*.fa', 'create,modify' )\n",
                        "        operator\t.subscribe { println \"File created or modified: $it\" }\n",
                        "        channel\t\n",
                        "\n",
                        "    \n",
                        "    Channel\n",
                        "        .fromPath(params.query)\n",
                        "        operator\t.branch{ }\n",
                        "        operator\t.splitFasta(by: params.chunkSize, file:true)\n",
                        "        operator\t.splitFasta{ }\n",
                        "        operator\t.set{ ch_fasta }\n",
                        "        operator\t.collect()\n",
                        "        operator\t.view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                        "        expression\tch_hits = blast(ch_fasta, db_dir)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "from lark import Lark\n",
                "\n",
                "## test_file = get_sample('1.nf')  ## parsing\n",
                "## test_file = get_sample('2.nf')  ## parsing\n",
                "test_file = get_sample('1.nf') \n",
                "#nextflow_grammar = Path(\"../nf_parser/grammer/nf.lark\").read_text()\n",
                "nextflow_grammar = Path(\"./grammers/nf.lark\").read_text()\n",
                "parser = Lark(nextflow_grammar, parser='lalr')\n",
                "tree = parser.parse(test_file)\n",
                "#print(tree)\n",
                "print(tree.pretty())"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "**transformers**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "## utils\n",
                "def flatten_list(lst):\n",
                "\tresult = []\n",
                "\tfor item in lst:\n",
                "\t\tif isinstance(item, list):\n",
                "\t\t\tresult.extend(flatten_list(item))\n",
                "\t\telse:\n",
                "\t\t\tresult.append(item)\n",
                "\treturn result"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 63,
            "metadata": {},
            "outputs": [],
            "source": [
                "## constructs\n",
                "from pydantic import validator, BaseModel, Field\n",
                "from typing import List, Optional, Any, Union, Dict\n",
                "\n",
                "class Comment(BaseModel):\n",
                "\ttext: str = Field(..., description=\"the comment textual value\")\n",
                "\n",
                "class Module(BaseModel):\n",
                "\t\"\"\" a nextflow [module](https://www.nextflow.io/docs/latest/module.html) \"\"\"\n",
                "\tpath: str = Field(..., description=\"the module path\")\n",
                "\timports: List[str] = Field(..., description=\"the module imports\")\n",
                "\n",
                "class Param(BaseModel):\n",
                "\t\"\"\" nextflow pipeline param \"\"\"\n",
                "\tname: str = Field(..., description=\"the param name\")\n",
                "\ttype: str = Field('string', description=\"the param type\")\n",
                "\tdefault_value: Optional[Union[str, int]] = Field(None, description=\"the param default value\")\n",
                "\tcomment: Optional[Comment] = Field(None, description=\"the param comment can be likened to its description\")\n",
                "\n",
                "class Expression(BaseModel):\n",
                "\t\"\"\" a call \"\"\"\n",
                "\tcode: str = Field(..., description=\"the expr code\")\n",
                "\n",
                "class Channel(Expression):\n",
                "\tpass\n",
                "\n",
                "class Arg(BaseModel):\n",
                "\t\"\"\" groovy function args \"\"\"\n",
                "\tname: str = Field(..., description=\"the arg\")\n",
                "\t#type: str = Field('string', description=\"the param type\")\n",
                "\n",
                "class Function(BaseModel):\n",
                "\tname: str = Field(..., description=\"the func name\")\n",
                "\targs: Optional[List[Arg]] = Field(None, description=\"the func args\")\n",
                "\tcode: str = Field(None, description=\"the func code block\")\n",
                "\n",
                "class Script(BaseModel):\n",
                "\ttype: str = Field(\"bash\", description=\"the script type\")\n",
                "\tcode: str = Field(..., description=\"the script source code text\")\n",
                "\ttemplate: Optional[str] = Field(None, description=\"path to shell script if template was provided. see [nextflow script template docs](https://www.nextflow.io/docs/latest/process.html#template)\")\n",
                "\tcondition: Optional[str] = Field(None, description=\"script conditional control flow expression type. see [nextflow conditional-scripts docs](https://www.nextflow.io/docs/latest/process.html#conditional-scripts)\")\n",
                "\n",
                "class Directive(BaseModel):\n",
                "\tname: str = Field(..., description=\"the directive name\")\n",
                "\tvalue: str = Field(..., description=\"the directive value\")\n",
                "\toptions: Dict[str, Any] = Field(None, description=\"the directive options\")\n",
                "\n",
                "class Input(BaseModel):\n",
                "\tname: str = Field(..., description=\"the type\")\n",
                "\tvalue: Union[str, List[str]] = Field(..., description=\"the value\")\n",
                "\tcomment: Optional[Comment] = None\n",
                "\n",
                "class Output(Input):\n",
                "\tpass\n",
                "\n",
                "class Process(BaseModel):\n",
                "\tname: str = Field(..., description=\"the process name\")\n",
                "\tinputs: List[Input] = []\n",
                "\toutputs: List[Output] = []\n",
                "\tcomments: List[Comment] = None\n",
                "\tscripts: List[Script] = None\n",
                "\tdirectives: List[Directive] = None\n",
                "\n",
                "class Workflow(BaseModel):\n",
                "\tname: str = Field('main', description=\"the workflow name\")\n",
                "\tinputs: Optional[List[Input]] = Field(None, description=\"the workflow inputs aka `take`\")\n",
                "\toutputs: Optional[List[Output]] = Field(None, description=\"the workflow outputs aka `emit`\")\n",
                "\texpressions: List[Union[Expression, Channel]] = Field(None, description=\"the workflow expressions\")\n",
                "\t#channels: Any = Field(None, description=\"the workflow channel expressions ie. data flow statements\")\n",
                "\tcomments: List[Comment] = None\n",
                "\t\n",
                "class Pipeline(BaseModel):\n",
                "\t\"\"\" a nextflow pipeline  \"\"\"\n",
                "\tmodules: Optional[List[Module]] = Field(None, description=\"the nextflow [modules](https://www.nextflow.io/docs/latest/module.html)\")\n",
                "\tparams: Optional[List[Param]] = Field(None, description=\"the nextflow [params](https://www.nextflow.io/docs/latest/basic.html#processes-and-channels)\")\n",
                "\tprocesses: Optional[List[Process]] = Field(None, description=\"the nextflow [processes](https://www.nextflow.io/docs/latest/process.html)\")\n",
                "\tworkflows: Optional[List[Workflow]] = Field(None, description=\"the nextflow [workflows](https://www.nextflow.io/docs/latest/workflow.html)\")\n",
                "\tfunctions: Optional[List[Function]] = Field(None, description=\"pipeline defined functions\")\n",
                "\tcomments: Optional[List[Comment]] = Field(None, description=\"pipeline level comments\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 65,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "workflow.expression: db_name = file(params.db).name\n",
                        "workflow.expression: db_dir = file(params.db).parent\n",
                        "module_import: ['foo', \"'./module/1.nf'\"]\n",
                        "module_import: ['BAR', \"'./module/2.nf'\"]\n",
                        "workflow.expression: db_name = file(params.db).name\n",
                        "container: 'python' None\n",
                        "directive: name='container' value=\"'python'\" options=None\n",
                        "script: [Comment(text='// script comment'), Script(type='shell', code=\"'''\\n    echo 'hello' >  sample.txt\\n    '''\", template=None, condition=None)]\n",
                        "process_block: [Directive(name='container', value=\"'python'\", options=None), Output(name='path', value=\"'sample.txt'\", comment=None), Comment(text='// script comment'), Script(type='shell', code=\"'''\\n    echo 'hello' >  sample.txt\\n    '''\", template=None, condition=None)]\n",
                        "process: {'inputs': [], 'outputs': [Output(name='path', value=\"'sample.txt'\", comment=None)], 'comments': [Comment(text='// script comment')], 'scripts': [Script(type='shell', code=\"'''\\n    echo 'hello' >  sample.txt\\n    '''\", template=None, condition=None)], 'directives': [Directive(name='container', value=\"'python'\", options=None)]}\n",
                        "workflow.expression:  \n",
                        "\n",
                        "    foo()\n",
                        "workflow.main: [Expression(code=' \\n\\n    foo()')]\n",
                        "workflow_block: [Expression(code=' \\n\\n    foo()')]\n",
                        "workflow: [[Expression(code=' \\n\\n    foo()')]] None\n",
                        "workflow: main [Expression(code=' \\n\\n    foo()')] []\n",
                        "workflow.expression: \n",
                        "    foo()\n",
                        "workflow.main: [Expression(code='\\n    foo()')]\n",
                        "workflow.main: [Comment(text=\"/*\\n     * Create a channel emitting the given query fasta file(s).\\n     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\\n     * Finally, assign the resulting channel to the variable 'ch_fasta'\\n     */\"), Channel(code='\\n    Channel\\n        .fromPath(params.query)'), '.splitFasta(by: params.chunkSize, file:true)', '.set { ch_fasta }']\n",
                        "workflow.expression: ch_hits = blast(ch_fasta, db_dir)\n",
                        "workflow.main: [Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), Expression(code='ch_hits = blast(ch_fasta, db_dir)')]\n",
                        "workflow.main: [Comment(text='// define a channel emitting three values'), Channel(code=\"source = Channel.of( 'alpha', 'beta', 'delta' )\")]\n",
                        "workflow.expression: ch_hits = blast(ch_fasta, db_dir)\n",
                        "workflow.main: [Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), 'ch_sequences\\n        .collectFile(name: params.out)', '.view { file -> \"matching sequences:\\\\n ${file.text}\" }', Channel(code=\"\\n    \\n    Channel\\n        .watchPath( '/path/*.fa' )\"), '.subscribe { println \"Fasta file: $it\" }', Channel(code=\"\\n\\n    Channel\\n        .watchPath( '/path/*.fa', 'create,modify' )\"), '.subscribe { println \"File created or modified: $it\" }', Channel(code='\\n\\n    \\n    Channel\\n        .fromPath(params.query)'), '.branch{ }', '.splitFasta(by: params.chunkSize, file:true)', '.splitFasta{ }', '.set{ ch_fasta }', '.collect()', '.view { file -> \"matching sequences:\\\\n ${file.text}\" }', Expression(code='ch_hits = blast(ch_fasta, db_dir)')]\n",
                        "workflow_block: [Expression(code='\\n    foo()'), Comment(text=\"/*\\n     * Create a channel emitting the given query fasta file(s).\\n     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\\n     * Finally, assign the resulting channel to the variable 'ch_fasta'\\n     */\"), Channel(code='\\n    Channel\\n        .fromPath(params.query)'), '.splitFasta(by: params.chunkSize, file:true)', '.set { ch_fasta }', Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), Expression(code='ch_hits = blast(ch_fasta, db_dir)'), Comment(text='// define a channel emitting three values'), Channel(code=\"source = Channel.of( 'alpha', 'beta', 'delta' )\"), Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), 'ch_sequences\\n        .collectFile(name: params.out)', '.view { file -> \"matching sequences:\\\\n ${file.text}\" }', Channel(code=\"\\n    \\n    Channel\\n        .watchPath( '/path/*.fa' )\"), '.subscribe { println \"Fasta file: $it\" }', Channel(code=\"\\n\\n    Channel\\n        .watchPath( '/path/*.fa', 'create,modify' )\"), '.subscribe { println \"File created or modified: $it\" }', Channel(code='\\n\\n    \\n    Channel\\n        .fromPath(params.query)'), '.branch{ }', '.splitFasta(by: params.chunkSize, file:true)', '.splitFasta{ }', '.set{ ch_fasta }', '.collect()', '.view { file -> \"matching sequences:\\\\n ${file.text}\" }', Expression(code='ch_hits = blast(ch_fasta, db_dir)')]\n",
                        "workflow: ['jimmy', [Expression(code='\\n    foo()'), Comment(text=\"/*\\n     * Create a channel emitting the given query fasta file(s).\\n     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\\n     * Finally, assign the resulting channel to the variable 'ch_fasta'\\n     */\"), Channel(code='\\n    Channel\\n        .fromPath(params.query)'), '.splitFasta(by: params.chunkSize, file:true)', '.set { ch_fasta }', Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), Expression(code='ch_hits = blast(ch_fasta, db_dir)'), Comment(text='// define a channel emitting three values'), Channel(code=\"source = Channel.of( 'alpha', 'beta', 'delta' )\"), Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), 'ch_sequences\\n        .collectFile(name: params.out)', '.view { file -> \"matching sequences:\\\\n ${file.text}\" }', Channel(code=\"\\n    \\n    Channel\\n        .watchPath( '/path/*.fa' )\"), '.subscribe { println \"Fasta file: $it\" }', Channel(code=\"\\n\\n    Channel\\n        .watchPath( '/path/*.fa', 'create,modify' )\"), '.subscribe { println \"File created or modified: $it\" }', Channel(code='\\n\\n    \\n    Channel\\n        .fromPath(params.query)'), '.branch{ }', '.splitFasta(by: params.chunkSize, file:true)', '.splitFasta{ }', '.set{ ch_fasta }', '.collect()', '.view { file -> \"matching sequences:\\\\n ${file.text}\" }', Expression(code='ch_hits = blast(ch_fasta, db_dir)')]] None\n",
                        "workflow: main [Expression(code='\\n    foo()'), Channel(code='\\n    Channel\\n        .fromPath(params.query)'), Expression(code='ch_hits = blast(ch_fasta, db_dir)'), Channel(code=\"source = Channel.of( 'alpha', 'beta', 'delta' )\"), Channel(code=\"\\n    \\n    Channel\\n        .watchPath( '/path/*.fa' )\"), Channel(code=\"\\n\\n    Channel\\n        .watchPath( '/path/*.fa', 'create,modify' )\"), Channel(code='\\n\\n    \\n    Channel\\n        .fromPath(params.query)'), Expression(code='ch_hits = blast(ch_fasta, db_dir)')] [Comment(text=\"/*\\n     * Create a channel emitting the given query fasta file(s).\\n     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\\n     * Finally, assign the resulting channel to the variable 'ch_fasta'\\n     */\"), Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), Comment(text='// define a channel emitting three values'), Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\")]\n",
                        "\n",
                        "\n",
                        "--Results:--\n",
                        " modules=[Module(path=\"'./module/1.nf'\", imports=['foo']), Module(path=\"'./module/2.nf'\", imports=['BAR'])] params=[Param(name='query', type='string', default_value='\"$baseDir/data/sample.fa\"', comment=None), Param(name='db', type='string', default_value='\"$baseDir/blast-db/pdb/tiny\"', comment=None), Param(name='out', type='string', default_value='\"result.txt\"', comment=None), Param(name='chunkSize', type='string', default_value='100', comment=None), Param(name='in', type='string', default_value='\"$baseDir/data/sample.fa\"', comment=Comment(text='// path to fa file')), Param(name='query', type='string', default_value='\"$baseDir/data/sample.fa\"', comment=None), Param(name='db', type='string', default_value='\"$baseDir/blast-db/pdb/tiny\"', comment=None), Param(name='out', type='string', default_value='\"result.txt\"', comment=None), Param(name='chunkSize', type='string', default_value='100', comment=None)] processes=[Process(name='foo', inputs=[], outputs=[Output(name='path', value=\"'sample.txt'\", comment=None)], comments=[Comment(text='// script comment')], scripts=[Script(type='shell', code=\"'''\\n    echo 'hello' >  sample.txt\\n    '''\", template=None, condition=None)], directives=[Directive(name='container', value=\"'python'\", options=None)])] workflows=[Workflow(name='main', inputs=None, outputs=None, expressions=[Expression(code=' \\n\\n    foo()')], comments=None), Workflow(name='main', inputs=None, outputs=None, expressions=[Expression(code='\\n    foo()'), Channel(code='\\n    Channel\\n        .fromPath(params.query)'), Expression(code='ch_hits = blast(ch_fasta, db_dir)'), Channel(code=\"source = Channel.of( 'alpha', 'beta', 'delta' )\"), Channel(code=\"\\n    \\n    Channel\\n        .watchPath( '/path/*.fa' )\"), Channel(code=\"\\n\\n    Channel\\n        .watchPath( '/path/*.fa', 'create,modify' )\"), Channel(code='\\n\\n    \\n    Channel\\n        .fromPath(params.query)'), Expression(code='ch_hits = blast(ch_fasta, db_dir)')], comments=[Comment(text=\"/*\\n     * Create a channel emitting the given query fasta file(s).\\n     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\\n     * Finally, assign the resulting channel to the variable 'ch_fasta'\\n     */\"), Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\"), Comment(text='// define a channel emitting three values'), Comment(text=\"/*\\n     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\\n     * and emit the resulting BLAST matches.\\n     */\")])] functions=None comments=None\n"
                    ]
                }
            ],
            "source": [
                "from lark import Transformer, v_args, Discard\n",
                "from typing import List\n",
                "\n",
                "@v_args(inline=True)\n",
                "class NextflowTransformer(Transformer):\n",
                "\tproceses: List[Process] = []\n",
                "\t#def __default__(self, data, c, h):\n",
                "\t#\treturn Discard\n",
                "\tCNAME = lambda _, v: str(v)\n",
                "\tSTRING = lambda _, v: str(v)\n",
                "\tfloat = lambda _, v: float(v)\n",
                "\tint = lambda _, v: int(v)\n",
                "\tstring = lambda _, v: str(v)\n",
                "\tvariable = lambda _, v: str(v)\n",
                "\tmap = lambda _, k, v: {k: v}\n",
                "\n",
                "\tdef __init__(self):\n",
                "\t\tsuper().__init__()\n",
                "\t\n",
                "\t@v_args(inline=False)\n",
                "\tdef start(self, items) -> Pipeline:\n",
                "\t\tcomments, modules,  processes, workflows, params, functions = None, None, None, None, None, None\n",
                "\t\tfor item in items:\n",
                "\t\t\tif type(item) == Comment:\n",
                "\t\t\t\tif not comments:\n",
                "\t\t\t\t\tcomments = []\n",
                "\t\t\t\tcomments.append(item)\n",
                "\t\t\telif type(item) == Module:\n",
                "\t\t\t\tif not modules:\n",
                "\t\t\t\t\tmodules = []\n",
                "\t\t\t\tmodules.append(item)\n",
                "\t\t\telif type(item) == Param:\n",
                "\t\t\t\tif not params:\n",
                "\t\t\t\t\tparams = []\n",
                "\t\t\t\tparams.append(item)\n",
                "\t\t\telif type(item) == Process:\n",
                "\t\t\t\tif not processes:\n",
                "\t\t\t\t\tprocesses = []\n",
                "\t\t\t\tprocesses.append(item)\n",
                "\t\t\telif type(item) == Workflow:\n",
                "\t\t\t\tif not workflows:\n",
                "\t\t\t\t\tworkflows = []\n",
                "\t\t\t\tworkflows.append(item)\n",
                "\t\t\telif type(item) == Function:\n",
                "\t\t\t\tif not functions:\n",
                "\t\t\t\t\tfunctions = []\n",
                "\t\t\t\tfunctions.append(item)\n",
                "\t\tpipeline = Pipeline(\n",
                "\t\t\tmodules=modules, \n",
                "\t\t\tparams=params, \n",
                "\t\t\tprocesses=processes, \n",
                "\t\t\tfunctions=functions,\n",
                "\t\t\tworkflows=workflows\n",
                "\t\t)\n",
                "\t\treturn pipeline\n",
                "\t\t\n",
                "\t\n",
                "\tdef dsl(self, item):\n",
                "\t\tpass\n",
                "\n",
                "\tdef comment(self, item):\n",
                "\t\treturn Comment(text=str(item))\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef module_import(self, items):\n",
                "\t\tprint(\"module_import:\", items)\n",
                "\t\tmod_path = items[-1]\n",
                "\t\tmods = items[:-1]\n",
                "\t\treturn Module(path=mod_path, imports=mods)\n",
                "\n",
                "\tdef param(self, name, default_val=None, comment=None):\n",
                "\t\t# todo: detect the param value type from use or default_value\n",
                "\t\t_type = 'string'\n",
                "\t\treturn Param(name=name, type=_type, default_value=default_val, comment=comment)\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef function(self, items:list):\n",
                "\t\tprint(\"function:\", items)\n",
                "\t\tname, code = items.pop(0) , items.pop(-1)\n",
                "\t\targs = []\n",
                "\t\tif items:\n",
                "\t\t\targs = items[0]\n",
                "\t\t#print(\"args:\", args)\n",
                "\t\treturn Function(name=name, code=code, args=args)\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef workflow(self, name, items=None):\n",
                "\t\tprint('workflow:', name, items)\n",
                "\t\tif not items:\n",
                "\t\t\titems = name\n",
                "\t\t\tname = 'main'\n",
                "\t\tcomments, expressions, channels = [], [], []\n",
                "\t\tfor item in flatten_list(items):\n",
                "\t\t\tif type(item) == Comment:\n",
                "\t\t\t\tcomments.append(item)\n",
                "\t\t\telif type(item) == Expression:\n",
                "\t\t\t\texpressions.append(item)\n",
                "\t\t\telif isinstance(item, Expression):\n",
                "\t\t\t\texpressions.append(item)\n",
                "\t\tprint('workflow:', name, expressions, comments)\n",
                "\t\treturn Workflow(\n",
                "\t\t\tname=name, \n",
                "\t\t\texpressions=expressions, \n",
                "\t\t\t#channels=channels, \n",
                "\t\t\tcomments=comments or None\n",
                "\t\t)\n",
                "\n",
                "\tdef process(self, name, items) -> Process:\n",
                "\t\tprint('process:',items)\n",
                "\t\treturn Process(name=name, **items)\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef workflow_block(self, items):\n",
                "\t\titems = flatten_list(items)\n",
                "\t\tprint('workflow_block:', items)\n",
                "\t\treturn items\n",
                "\n",
                "\tdef workflow_input(self, item):\n",
                "\t\treturn Input(name=\"take\", value=item)\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef main(self, items):\n",
                "\t\titems = flatten_list(items)\n",
                "\t\tprint('workflow.main:',items)\n",
                "\t\treturn items\n",
                "\n",
                "\tdef emit(self, items):\n",
                "\t\treturn items\n",
                "\n",
                "\tdef wf_output(self, item):\n",
                "\t\treturn Output(name=\"emit\", value=str(item))\n",
                "\n",
                "\tdef channel(self, item):\n",
                "\t\treturn Channel(code=str(item))\n",
                "\n",
                "\tdef expression(self, item):\n",
                "\t\tprint('workflow.expression:', item)\n",
                "\t\treturn Expression(code=str(item))\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef process_block(self, items):\n",
                "\t\tinputs, outputs, comments, scripts, directives = [], [], [], [], []\n",
                "\t\titems = flatten_list(items)\n",
                "\t\tprint(\"process_block:\", items)\n",
                "\t\tfor item in items:\n",
                "\t\t\tif isinstance(item, Comment):\n",
                "\t\t\t\tcomments.append(item)\n",
                "\t\t\telif type(item) == Input:\n",
                "\t\t\t\tinputs.append(item)\n",
                "\t\t\telif type(item) == Output:\n",
                "\t\t\t\toutputs.append(item)\n",
                "\t\t\telif type(item) == Script:\n",
                "\t\t\t\tscripts.append(item)\n",
                "\t\t\telif type(item) == Directive:\n",
                "\t\t\t\tdirectives.append(item)\n",
                "\t\t\t\n",
                "\t\treturn {\n",
                "\t\t\t\"inputs\": inputs,\n",
                "\t\t\t\"outputs\": outputs,\n",
                "\t\t\t\"comments\": comments, \n",
                "\t\t\t\"scripts\": scripts,\n",
                "\t\t\t\"directives\": directives,\n",
                "\t\t}\n",
                "\t\t#return f'Process Block: {items}'\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef input(self, items):\n",
                "\t\titems = flatten_list(items)\n",
                "\t\t#print('input:', items)\n",
                "\t\tout = []\n",
                "\t\tfor x in items:\n",
                "\t\t\tif isinstance(x, dict):\n",
                "\t\t\t\tx = Input(**x)\n",
                "\t\t\tout.append(x)\n",
                "\t\t#print('input-transformed:', items)\n",
                "\t\treturn out\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef output(self, items):\n",
                "\t\titems = flatten_list(items)\n",
                "\t\t#print('output:', items)\n",
                "\t\tout = []\n",
                "\t\tfor x in items:\n",
                "\t\t\tif isinstance(x, dict):\n",
                "\t\t\t\tx = Output(**x)\n",
                "\t\t\tout.append(x)\n",
                "\t\t#print('output-transformed:', items)\n",
                "\t\treturn out\n",
                "\t\n",
                "\t@v_args(inline=False)\n",
                "\tdef script(self, items):\n",
                "\t\t#items = flatten_list(items)\n",
                "\t\tprint('script:', items)\n",
                "\t\treturn items\n",
                "\n",
                "\tdef shell(self, items):\n",
                "\t\treturn items\n",
                "\n",
                "\tdef exec(self, val):\n",
                "\t\t## todo: improve grammer parsing, might break\n",
                "\t\treturn Script(type=\"exec\", code=str(val))\n",
                "\n",
                "\tdef directive(self, item):\n",
                "\t\tprint('directive:', item)\n",
                "\t\treturn item\n",
                "\n",
                "\tdef bash_script(self, val):\n",
                "\t\t## todo: check the shebang of script if provided to annotate correct script type\n",
                "\t\treturn Script(type=\"bash\", code=str(val))\n",
                "\n",
                "\tdef shell_script(self, val):\n",
                "\t\treturn Script(type=\"shell\", code=str(val))\n",
                "\n",
                "\tdef template(self, val):\n",
                "\t\t# todo: get the script template source from the template path\n",
                "\t\treturn Script(type=\"shell\", code=str(val), template=str(val))\n",
                "\n",
                "\tdef if_script(self, val):\n",
                "\t\t## todo: separate condition from expression\n",
                "\t\treturn Script(type=\"bash\", code=str(val), condition=\"if\")\n",
                "\n",
                "\tdef elif_script(self, val):\n",
                "\t\t## todo: separate condition from expression\n",
                "\t\treturn Script(type=\"bash\", code=str(val), condition=\"elif\")\n",
                "\n",
                "\tdef else_script(self, val):\n",
                "\t\t## todo: separate condition from expression\n",
                "\t\treturn Script(type=\"bash\", code=str(val), condition=\"else\")\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef conditional_script(self, items):\n",
                "\t\tprint('conditional_script:', items)\n",
                "\t\treturn items\n",
                "\n",
                "\tdef val(self, value):\n",
                "\t\treturn {\"name\":\"val\", \"value\":value}\n",
                "\n",
                "\tdef file(self, value):\n",
                "\t\tprint('file:', value)\n",
                "\t\treturn {\"name\":\"file\", \"value\":value}\n",
                "\t\n",
                "\tdef path(self, value):\n",
                "\t\treturn {\"name\":\"path\", \"value\":value}\n",
                "\t\n",
                "\tdef env(self, value):\n",
                "\t\treturn {\"name\":\"env\", \"value\":value}\n",
                "\t\n",
                "\tdef stdin(self, value):\n",
                "\t\treturn {\"name\":\"stdin\", \"value\":value}\n",
                "\n",
                "\tdef tuple(self, value):\n",
                "\t\treturn {\"name\":\"tuple\", \"value\":value}\n",
                "\t\n",
                "\tdef each(self, value):\n",
                "\t\treturn {\"name\":\"each\", \"value\":value}\n",
                "\n",
                "\tdef accelerator(self, val, options=None):\n",
                "\t\tprint(f'queue:', val, options)\n",
                "\t\treturn Directive(name=\"accelerator\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef before_script(self, val, options=None):\n",
                "\t\tprint(f'before_script:', val, options)\n",
                "\t\treturn Directive(name=\"before_script\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef after_script(self, val, options=None):\n",
                "\t\tprint(f'after_script:', val, options)\n",
                "\t\treturn Directive(name=\"after_script\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef cluster_options(self, val, options=None):\n",
                "\t\tprint(f'cluster_options:', val, options)\n",
                "\t\treturn Directive(name=\"cluster_options\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef conda(self, val, options=None):\n",
                "\t\tprint(f'conda:', val, options)\n",
                "\t\treturn Directive(name=\"conda\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef cache(self, val, options=None):\n",
                "\t\tprint(f'cache:', val, options)\n",
                "\t\treturn Directive(name=\"cache\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef cpus(self, val, options=None):\n",
                "\t\tprint(f'cpus:', val, options)\n",
                "\t\treturn Directive(name=\"cpus\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef container(self, val, options=None):\n",
                "\t\tprint(f'container:', val, options)\n",
                "\t\treturn Directive(name=\"container\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef container_options(self, val, options=None):\n",
                "\t\tprint(f'container_options:', val, options)\n",
                "\t\treturn Directive(name=\"container_options\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef debug(self, val, options=None):\n",
                "\t\tprint(f'debug:', val, options)\n",
                "\t\treturn Directive(name=\"debug\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef disk(self, val, options=None):\n",
                "\t\tprint(f'disk:', val, options)\n",
                "\t\treturn Directive(name=\"disk\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef echo(self, val, options=None):\n",
                "\t\tprint(f'echo:', val, options)\n",
                "\t\treturn Directive(name=\"echo\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef error_strategy(self, val, options=None):\n",
                "\t\tprint(f'error_strategy:', val, options)\n",
                "\t\treturn Directive(name=\"error_strategy\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef executor(self, val, options=None):\n",
                "\t\tprint(f'executor:', val, options)\n",
                "\t\treturn Directive(name=\"executor\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef ext(self, val, options=None):\n",
                "\t\tprint(f'ext:', val, options)\n",
                "\t\treturn Directive(name=\"ext\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef fair(self, val, options=None):\n",
                "\t\tprint(f'fair:', val, options)\n",
                "\t\treturn Directive(name=\"fair\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef label(self, val, options=None):\n",
                "\t\tprint(f'label:', val, options)\n",
                "\t\treturn Directive(name=\"label\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef machine_type(self, val, options=None):\n",
                "\t\tprint(f'machine_type:', val, options)\n",
                "\t\treturn Directive(name=\"machine_type\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef max_errors(self, val, options=None):\n",
                "\t\tprint(f'max_errors:', val, options)\n",
                "\t\treturn Directive(name=\"max_errors\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef max_forks(self, val, options=None):\n",
                "\t\tprint(f'max_forks:', val, options)\n",
                "\t\treturn Directive(name=\"max_forks\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef max_retries(self, val, options=None):\n",
                "\t\tprint(f'max_retries:', val, options)\n",
                "\t\treturn Directive(name=\"max_retries\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef memory(self, val, options=None):\n",
                "\t\tprint(f'memory:', val, options)\n",
                "\t\treturn Directive(name=\"memory\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef module(self, val, options=None):\n",
                "\t\tprint(f'module:', val, options)\n",
                "\t\treturn Directive(name=\"module\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef penv(self, val, options=None):\n",
                "\t\tprint(f'penv:', val, options)\n",
                "\t\treturn Directive(name=\"penv\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef pod(self, val, options=None):\n",
                "\t\tprint(f'pod:', val, options)\n",
                "\t\treturn Directive(name=\"pod\", value=str(val), options=options)\n",
                "\t\n",
                "\t#@v_args(inline=False)\n",
                "\tdef publish_dir(self, val, options=None):\n",
                "\t\tprint(f'publish_dir:', val, options)\n",
                "\t\treturn Directive(name=\"publish_dir\", value=str(val), options=options)\n",
                "\n",
                "\tdef queue(self, val, options=None):\n",
                "\t\tprint(f'queue:', val, options)\n",
                "\t\treturn Directive(name=\"queue\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef resource_labels(self, val, options=None):\n",
                "\t\tprint(f'resource_labels:', val, options)\n",
                "\t\treturn Directive(name=\"resource_labels\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef scratch(self, val, options=None):\n",
                "\t\tprint(f'scratch:', val, options)\n",
                "\t\treturn Directive(name=\"scratch\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef spack(self, val, options=None):\n",
                "\t\tprint(f'spack:', val, options)\n",
                "\t\treturn Directive(name=\"spack\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef store_dir(self, val, options=None):\n",
                "\t\tprint(f'store_dir:', val, options)\n",
                "\t\treturn Directive(name=\"store_dir\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef stage_in_mode(self, val, options=None):\n",
                "\t\tprint(f'stage_in_mode:', val, options)\n",
                "\t\treturn Directive(name=\"stage_in_mode\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef stage_out_mode(self, val, options=None):\n",
                "\t\tprint(f'stage_out_mode:', val, options)\n",
                "\t\treturn Directive(name=\"stage_out_mode\", value=str(val), options=options)\n",
                "\t\n",
                "\tdef tag(self, val, options=None):\n",
                "\t\tprint(f'tag:', val, options)\n",
                "\t\treturn Directive(name=\"tag\", value=str(val), options=options)\n",
                "\n",
                "\tdef time(self, val, options=None):\n",
                "\t\tprint(f'time:', val, options)\n",
                "\t\treturn Directive(name=\"time\", value=str(val), options=options)\n",
                "\n",
                "\t@v_args(inline=False)\n",
                "\tdef args(self, items):\n",
                "\t\titems = flatten_list(items)\n",
                "\t\t#print(\"args::\", items)\n",
                "\t\treturn items\n",
                "\n",
                "\tdef arg(self, name):\n",
                "\t\treturn Arg(name=name) \n",
                "\n",
                "\tdef identifier(self, val):\n",
                "\t\treturn val\n",
                "\n",
                "\tdef declaration(self, val):\n",
                "\t\treturn val\n",
                "\n",
                "\tdef value(self, val):\n",
                "\t\treturn val\n",
                "\n",
                "\tdef code_block(self, val):\n",
                "\t\treturn str(val)\n",
                "\n",
                "\tdef statement(self, val):\n",
                "\t\treturn str(val)\n",
                "\n",
                "\tdef operator(self, val):\n",
                "\t\t## todo\n",
                "\t\treturn str(val)\n",
                "\n",
                "## testing transformer\n",
                "transformer=NextflowTransformer()\n",
                "data:Pipeline = transformer.transform(tree)\n",
                "print(\"\\n\\n--Results:--\\n\", data)\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
