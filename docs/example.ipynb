{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Example usage\n",
                "\n",
                "To use `nf_parser` in a project:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nf_parser\n",
                "\n",
                "print(nf_parser.__version__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 194,
            "metadata": {},
            "outputs": [],
            "source": [
                "## test passing\n",
                "test_1 = \"\"\"#!/usr/bin/env nextflow\n",
                " \n",
                "/*\n",
                " * Defines the pipeline input parameters (with a default value for each one).\n",
                " * Each of the following parameters can be specified as command line options.\n",
                " */\n",
                "params.query = \"$baseDir/data/sample.fa\"\n",
                "params.db = \"$baseDir/blast-db/pdb/tiny\"\n",
                "params.out = \"result.txt\"\n",
                "params.chunkSize = 100\n",
                " \n",
                "db_name = file(params.db).name\n",
                "db_dir = file(params.db).parent\n",
                " \n",
                "\n",
                "nextflow.enable.dsl=2\n",
                "\n",
                "include { foo } from './module/1.nf'\n",
                "include { BAR } from './module/2.nf'\n",
                "\n",
                "db_name = file(params.db).name\n",
                "\n",
                "//def sayHello() {\n",
                "//    println \"$params.foo $params.bar\"\n",
                "//}\n",
                "\n",
                "Channel.fromPath(params.query)\n",
                "\n",
                "/*\n",
                " * Defines the pipeline input parameters (with a default value for each one).\n",
                " * Each of the following parameters can be specified as command line options.\n",
                " */\n",
                "params.in = \"$baseDir/data/sample.fa\" // path to fa file\n",
                "// some comment\n",
                "params.query = \"$baseDir/data/sample.fa\"\n",
                "params.db = \"$baseDir/blast-db/pdb/tiny\"\n",
                "params.out = \"result.txt\"\n",
                "params.chunkSize = 100\n",
                "\n",
                "process foo {\n",
                "    container 'python'\n",
                "\n",
                "    output:\n",
                "    path 'sample.txt'\n",
                "\n",
                "    shell:\n",
                "    '''\n",
                "    echo 'hello' >  sample.txt\n",
                "    '''\n",
                "}\n",
                "\n",
                "workflow  { \n",
                "\n",
                "    foo()\n",
                "}\n",
                "\n",
                "workflow jimmy {\n",
                "    foo()\n",
                "    /*\n",
                "     * Create a channel emitting the given query fasta file(s).\n",
                "     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\n",
                "     * Finally, assign the resulting channel to the variable 'ch_fasta'\n",
                "     */\n",
                "    Channel\n",
                "        .fromPath(params.query)\n",
                "        .splitFasta(by: params.chunkSize, file:true)\n",
                "        .set { ch_fasta }\n",
                "    \n",
                "    /*\n",
                "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                "     * and emit the resulting BLAST matches.\n",
                "     */\n",
                "    ch_hits = blast(ch_fasta, db_dir)\n",
                " \n",
                "\n",
                "    // define a channel emitting three values\n",
                "    source = Channel.of( 'alpha', 'beta', 'delta' )\n",
                "    \n",
                "    \n",
                "    /*\n",
                "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                "     * and emit the resulting BLAST matches.\n",
                "     */\n",
                "    ch_sequences\n",
                "        .collectFile(name: params.out)\n",
                "        .view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                "    \n",
                "    Channel\n",
                "        .watchPath( '/path/*.fa' )\n",
                "        .subscribe { println \"Fasta file: $it\" }\n",
                "\n",
                "    Channel\n",
                "        .watchPath( '/path/*.fa', 'create,modify' )\n",
                "        .subscribe { println \"File created or modified: $it\" }\n",
                "\n",
                "    \n",
                "    Channel\n",
                "        .fromPath(params.query)\n",
                "        .branch{ }\n",
                "        .splitFasta(by: params.chunkSize, file:true)\n",
                "        .splitFasta{ }\n",
                "        .set{ ch_fasta }\n",
                "        .collect()\n",
                "        .view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                "\n",
                "    ch_hits = blast(ch_fasta, db_dir)\n",
                "        \n",
                " \n",
                "}\n",
                "\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "workflow  { \n",
                "\n",
                "    ch_sequences\n",
                "        .collectFile(name: params.out)\n",
                "        .view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                "}"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 198,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "test_2 = ''' #!/usr/bin/env nextflow\n",
                " \n",
                "/*\n",
                " * Defines the pipeline input parameters (with a default value for each one).\n",
                " * Each of the following parameters can be specified as command line options.\n",
                " */\n",
                "params.query = \"$baseDir/data/sample.fa\"\n",
                "params.db = \"$baseDir/blast-db/pdb/tiny\"\n",
                "params.out = \"result.txt\"\n",
                "params.chunkSize = 100\n",
                " \n",
                "db_name = file(params.db).name\n",
                "db_dir = file(params.db).parent\n",
                " \n",
                " \n",
                "workflow {\n",
                "    /*\n",
                "     * Create a channel emitting the given query fasta file(s).\n",
                "     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\n",
                "     * Finally, assign the resulting channel to the variable 'ch_fasta'\n",
                "     */\n",
                "    Channel\n",
                "        .fromPath(params.query)\n",
                "        .splitFasta(by: params.chunkSize, file:true)\n",
                "        .set { ch_fasta }\n",
                " \n",
                "    /*\n",
                "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                "     * and emit the resulting BLAST matches.\n",
                "     */\n",
                "    ch_hits = blast(ch_fasta, db_dir)\n",
                " \n",
                "    /*\n",
                "     * Each time a file emitted by the 'blast' process, an extract job is executed,\n",
                "     * producing a file containing the matching sequences.\n",
                "     */\n",
                "    ch_sequences = extract(ch_hits, db_dir)\n",
                " \n",
                "    /*\n",
                "     * Collect all the sequences files into a single file\n",
                "     * and print the resulting file contents when complete.\n",
                "     */\n",
                "    ch_sequences\n",
                "        .collectFile(name: params.out)\n",
                "        .view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                "}\n",
                " \n",
                " \n",
                "process blast {\n",
                "    input:\n",
                "    path 'query.fa'\n",
                "    path db\n",
                " \n",
                "    output:\n",
                "    path 'top_hits'\n",
                " \n",
                "    \"\"\"\n",
                "    blastp -db $db/$db_name -query query.fa -outfmt 6 > blast_result\n",
                "    cat blast_result | head -n 10 | cut -f 2 > top_hits\n",
                "    \"\"\"\n",
                "}\n",
                " \n",
                " \n",
                "process extract {\n",
                "    input:\n",
                "    path 'top_hits'\n",
                "    path db\n",
                " \n",
                "    output:\n",
                "    path 'sequences'\n",
                " \n",
                "    \"\"\"\n",
                "    blastdbcmd -db $db/$db_name -entry_batch top_hits | head -n 10 > sequences\n",
                "    \"\"\"\n",
                "}\n",
                "'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 201,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "start\n",
                        "  shebang\t#!/usr/bin/env nextflow\n",
                        "  comment\t/*\n",
                        " * Defines the pipeline input parameters (with a default value for each one).\n",
                        " * Each of the following parameters can be specified as command line options.\n",
                        " */\n",
                        "  param\n",
                        "    query\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "  param\n",
                        "    db\n",
                        "    string\t\"$baseDir/blast-db/pdb/tiny\"\n",
                        "  param\n",
                        "    out\n",
                        "    string\t\"result.txt\"\n",
                        "  param\n",
                        "    chunkSize\n",
                        "    int\t100\n",
                        "  function_call\tdb_name = file(params.db).name\n",
                        "  function_call\tdb_dir = file(params.db).parent\n",
                        "  dsl\t2\n",
                        "  module_import\n",
                        "    foo\n",
                        "    './module/1.nf'\n",
                        "  module_import\n",
                        "    BAR\n",
                        "    './module/2.nf'\n",
                        "  function_call\tdb_name = file(params.db).name\n",
                        "  comment\t//def sayHello() {\n",
                        "  comment\t//    println \"$params.foo $params.bar\"\n",
                        "  comment\t//}\n",
                        "  channel\t\n",
                        "\n",
                        "Channel.fromPath(params.query)\n",
                        "  comment\t/*\n",
                        " * Defines the pipeline input parameters (with a default value for each one).\n",
                        " * Each of the following parameters can be specified as command line options.\n",
                        " */\n",
                        "  param\n",
                        "    in\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "    comment\t// path to fa file\n",
                        "  comment\t// some comment\n",
                        "  param\n",
                        "    query\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "  param\n",
                        "    db\n",
                        "    string\t\"$baseDir/blast-db/pdb/tiny\"\n",
                        "  param\n",
                        "    out\n",
                        "    string\t\"result.txt\"\n",
                        "  param\n",
                        "    chunkSize\n",
                        "    int\t100\n",
                        "  process\n",
                        "    foo\n",
                        "    process_block\n",
                        "      directive\n",
                        "        container\n",
                        "          string\t'python'\n",
                        "      output\n",
                        "        path\n",
                        "          declaration\t'sample.txt'\n",
                        "      shell\n",
                        "        shell_script\t'''\n",
                        "    echo 'hello' >  sample.txt\n",
                        "    '''\n",
                        "  workflow\n",
                        "    workflow_block\n",
                        "      main\n",
                        "        function_call\t \n",
                        "\n",
                        "    foo()\n",
                        "  workflow\n",
                        "    jimmy\n",
                        "    workflow_block\n",
                        "      main\n",
                        "        function_call\t\n",
                        "    foo()\n",
                        "      main\n",
                        "        comment\t/*\n",
                        "     * Create a channel emitting the given query fasta file(s).\n",
                        "     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\n",
                        "     * Finally, assign the resulting channel to the variable 'ch_fasta'\n",
                        "     */\n",
                        "        channel\t\n",
                        "    Channel\n",
                        "        .fromPath(params.query)\n",
                        "        operator\t.splitFasta(by: params.chunkSize, file:true)\n",
                        "        operator\t.set { ch_fasta }\n",
                        "      main\n",
                        "        comment\t/*\n",
                        "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                        "     * and emit the resulting BLAST matches.\n",
                        "     */\n",
                        "        function_call\tch_hits = blast(ch_fasta, db_dir)\n",
                        "      main\n",
                        "        comment\t// define a channel emitting three values\n",
                        "        channel\tsource = Channel.of( 'alpha', 'beta', 'delta' )\n",
                        "      main\n",
                        "        comment\t/*\n",
                        "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                        "     * and emit the resulting BLAST matches.\n",
                        "     */\n",
                        "        operator\tch_sequences\n",
                        "        .collectFile(name: params.out)\n",
                        "        operator\t.view { file -> \"matching sequences:\n",
                        " ${file.text}\" }\n",
                        "        channel\t\n",
                        "    \n",
                        "    Channel\n",
                        "        .watchPath( '/path/*.fa' )\n",
                        "        operator\t.subscribe { println \"Fasta file: $it\" }\n",
                        "        channel\t\n",
                        "\n",
                        "    Channel\n",
                        "        .watchPath( '/path/*.fa', 'create,modify' )\n",
                        "        operator\t.subscribe { println \"File created or modified: $it\" }\n",
                        "        channel\t\n",
                        "\n",
                        "    \n",
                        "    Channel\n",
                        "        .fromPath(params.query)\n",
                        "        operator\t.branch{ }\n",
                        "        operator\t.splitFasta(by: params.chunkSize, file:true)\n",
                        "        operator\t.splitFasta{ }\n",
                        "        operator\t.set{ ch_fasta }\n",
                        "        operator\t.collect()\n",
                        "        operator\t.view { file -> \"matching sequences:\n",
                        " ${file.text}\" }\n",
                        "        function_call\tch_hits = blast(ch_fasta, db_dir)\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "## # https://chat.openai.com/share/fb9d0650-3f66-4104-bff3-8697d5aeaf2e\n",
                "\n",
                "from pathlib import Path\n",
                "from lark import Lark\n",
                "\n",
                "test_file = test_1 \n",
                "#test_file = test_2 \n",
                "#test_file = test_2Channel\\.(fromList|fromPath|fromFilePairs|fromSRA|from|of|empty|value|watchPath)\\(((\\S+)(\\s+)?,?)?\\) \n",
                "#nextflow_grammar = Path(\"../nf_parser/grammer/nf.lark\").read_text()\n",
                "nextflow_grammar = Path(\"./grammers/nf.lark\").read_text()\n",
                "parser = Lark(nextflow_grammar, parser='lalr')\n",
                "tree = parser.parse(test_file)\n",
                "#print(tree)\n",
                "print(tree.pretty())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
