{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Example usage\n",
                "\n",
                "To use `nf_parser` in a project:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import nf_parser\n",
                "\n",
                "print(nf_parser.__version__)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 153,
            "metadata": {},
            "outputs": [],
            "source": [
                "## test passing\n",
                "test_1 = \"\"\"#!/usr/bin/env nextflow\n",
                "\n",
                "nextflow.enable.dsl=2\n",
                "\n",
                "include { foo } from './module/1.nf'\n",
                "include { BAR } from './module/2.nf'\n",
                "\n",
                "db_name = file(params.db).name\n",
                "\n",
                "//def sayHello() {\n",
                "//    println \"$params.foo $params.bar\"\n",
                "//}\n",
                "\n",
                "Channel.fromPath(params.query)\n",
                "\n",
                "/*\n",
                " * Defines the pipeline input parameters (with a default value for each one).\n",
                " * Each of the following parameters can be specified as command line options.\n",
                " */\n",
                "params.in = \"$baseDir/data/sample.fa\" // path to fa file\n",
                "// some comment\n",
                "params.query = \"$baseDir/data/sample.fa\"\n",
                "params.db = \"$baseDir/blast-db/pdb/tiny\"\n",
                "params.out = \"result.txt\"\n",
                "params.chunkSize = 100\n",
                "\n",
                "process foo {\n",
                "    container 'python'\n",
                "\n",
                "    output:\n",
                "    path 'sample.txt'\n",
                "\n",
                "    shell:\n",
                "    '''\n",
                "    echo 'hello' >  sample.txt\n",
                "    '''\n",
                "}\n",
                "\n",
                "workflow  {\n",
                "    foo()\n",
                "    Channel\n",
                "        .fromPath(params.query)\n",
                "        .splitFasta(by: params.chunkSize, file:true)\n",
                "        .collectFile(name: params.out)\n",
                "        //.set{ ch_fasta }\n",
                " \n",
                "}\n",
                "\"\"\""
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 108,
            "metadata": {},
            "outputs": [],
            "source": [
                "\n",
                "test_2 = ''' #!/usr/bin/env nextflow\n",
                " \n",
                "/*\n",
                " * Defines the pipeline input parameters (with a default value for each one).\n",
                " * Each of the following parameters can be specified as command line options.\n",
                " */\n",
                "params.query = \"$baseDir/data/sample.fa\"\n",
                "params.db = \"$baseDir/blast-db/pdb/tiny\"\n",
                "params.out = \"result.txt\"\n",
                "params.chunkSize = 100\n",
                " \n",
                "db_name = file(params.db).name\n",
                "db_dir = file(params.db).parent\n",
                " \n",
                " \n",
                "workflow {\n",
                "    /*\n",
                "     * Create a channel emitting the given query fasta file(s).\n",
                "     * Split the file into chunks containing as many sequences as defined by the parameter 'chunkSize'.\n",
                "     * Finally, assign the resulting channel to the variable 'ch_fasta'\n",
                "     */\n",
                "    Channel\n",
                "        .fromPath(params.query)\n",
                "        .splitFasta(by: params.chunkSize, file:true)\n",
                "        .set { ch_fasta }\n",
                " \n",
                "    /*\n",
                "     * Execute a BLAST job for each chunk emitted by the 'ch_fasta' channel\n",
                "     * and emit the resulting BLAST matches.\n",
                "     */\n",
                "    ch_hits = blast(ch_fasta, db_dir)\n",
                " \n",
                "    /*\n",
                "     * Each time a file emitted by the 'blast' process, an extract job is executed,\n",
                "     * producing a file containing the matching sequences.\n",
                "     */\n",
                "    ch_sequences = extract(ch_hits, db_dir)\n",
                " \n",
                "    /*\n",
                "     * Collect all the sequences files into a single file\n",
                "     * and print the resulting file contents when complete.\n",
                "     */\n",
                "    ch_sequences\n",
                "        .collectFile(name: params.out)\n",
                "        .view { file -> \"matching sequences:\\n ${file.text}\" }\n",
                "}\n",
                " \n",
                " \n",
                "process blast {\n",
                "    input:\n",
                "    path 'query.fa'\n",
                "    path db\n",
                " \n",
                "    output:\n",
                "    path 'top_hits'\n",
                " \n",
                "    \"\"\"\n",
                "    blastp -db $db/$db_name -query query.fa -outfmt 6 > blast_result\n",
                "    cat blast_result | head -n 10 | cut -f 2 > top_hits\n",
                "    \"\"\"\n",
                "}\n",
                " \n",
                " \n",
                "process extract {\n",
                "    input:\n",
                "    path 'top_hits'\n",
                "    path db\n",
                " \n",
                "    output:\n",
                "    path 'sequences'\n",
                " \n",
                "    \"\"\"\n",
                "    blastdbcmd -db $db/$db_name -entry_batch top_hits | head -n 10 > sequences\n",
                "    \"\"\"\n",
                "}\n",
                "'''"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 154,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Tree(Token('RULE', 'start'), [Tree(Token('RULE', 'shebang'), [Token('SH_COMMENT', '#!/usr/bin/env nextflow')]), Tree(Token('RULE', 'dsl'), [Token('INT', '2')]), Tree(Token('RULE', 'module_import'), [Token('CNAME', 'foo'), Token('STRING', \"'./module/1.nf'\")]), Tree(Token('RULE', 'module_import'), [Token('CNAME', 'BAR'), Token('STRING', \"'./module/2.nf'\")]), Tree(Token('RULE', 'function_call'), [Token('__ANON_3', 'db_name = file(params.db).name')]), Tree(Token('RULE', 'comment'), [Token('CPP_COMMENT', '//def sayHello() {')]), Tree(Token('RULE', 'comment'), [Token('CPP_COMMENT', '//    println \"$params.foo $params.bar\"')]), Tree(Token('RULE', 'comment'), [Token('CPP_COMMENT', '//}')]), Tree(Token('RULE', 'function_call'), [Token('__ANON_3', 'Channel.fromPath(params.query)')]), Tree(Token('RULE', 'comment'), [Token('C_COMMENT', '/*\\n * Defines the pipeline input parameters (with a default value for each one).\\n * Each of the following parameters can be specified as command line options.\\n */')]), Tree(Token('RULE', 'param'), [Token('CNAME', 'in'), Tree('string', [Token('DQUOTED_STRING', '\"$baseDir/data/sample.fa\"')]), Tree(Token('RULE', 'comment'), [Token('CPP_COMMENT', '// path to fa file')])]), Tree(Token('RULE', 'comment'), [Token('CPP_COMMENT', '// some comment')]), Tree(Token('RULE', 'param'), [Token('CNAME', 'query'), Tree('string', [Token('DQUOTED_STRING', '\"$baseDir/data/sample.fa\"')])]), Tree(Token('RULE', 'param'), [Token('CNAME', 'db'), Tree('string', [Token('DQUOTED_STRING', '\"$baseDir/blast-db/pdb/tiny\"')])]), Tree(Token('RULE', 'param'), [Token('CNAME', 'out'), Tree('string', [Token('DQUOTED_STRING', '\"result.txt\"')])]), Tree(Token('RULE', 'param'), [Token('CNAME', 'chunkSize'), Tree('int', [Token('INT', '100')])]), Tree(Token('RULE', 'process'), [Token('CNAME', 'foo'), Tree(Token('RULE', 'process_block'), [Tree(Token('RULE', 'directive'), [Tree(Token('RULE', 'container'), [Tree('string', [Token('SQUOTED_STRING', \"'python'\")])])]), Tree(Token('RULE', 'output'), [Tree(Token('RULE', 'path'), [Tree(Token('RULE', 'declaration'), [Token('STRING', \"'sample.txt'\")])])]), Tree(Token('RULE', 'shell'), [Tree(Token('RULE', 'shell_script'), [Token('__ANON_11', \"'''\\n    echo 'hello' >  sample.txt\\n    '''\")])])])]), Tree(Token('RULE', 'workflow'), [Tree(Token('RULE', 'workflow_block'), [Tree(Token('RULE', 'main'), [Tree(Token('RULE', 'function_call'), [Token('__ANON_3', 'foo()')]), Tree(Token('RULE', 'channel'), [Token('__ANON_2', 'Channel\\n        .fromPath(params.query)'), Tree('split_fasta', [Token('__ANON_48', '.splitFasta(by: params.chunkSize, file:true)\\n        .collectFile(name: params.out)')])])]), Tree(Token('RULE', 'comment'), [Token('CPP_COMMENT', '//.set{ ch_fasta }')])])])])\n",
                        "start\n",
                        "  shebang\t#!/usr/bin/env nextflow\n",
                        "  dsl\t2\n",
                        "  module_import\n",
                        "    foo\n",
                        "    './module/1.nf'\n",
                        "  module_import\n",
                        "    BAR\n",
                        "    './module/2.nf'\n",
                        "  function_call\tdb_name = file(params.db).name\n",
                        "  comment\t//def sayHello() {\n",
                        "  comment\t//    println \"$params.foo $params.bar\"\n",
                        "  comment\t//}\n",
                        "  function_call\tChannel.fromPath(params.query)\n",
                        "  comment\t/*\n",
                        " * Defines the pipeline input parameters (with a default value for each one).\n",
                        " * Each of the following parameters can be specified as command line options.\n",
                        " */\n",
                        "  param\n",
                        "    in\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "    comment\t// path to fa file\n",
                        "  comment\t// some comment\n",
                        "  param\n",
                        "    query\n",
                        "    string\t\"$baseDir/data/sample.fa\"\n",
                        "  param\n",
                        "    db\n",
                        "    string\t\"$baseDir/blast-db/pdb/tiny\"\n",
                        "  param\n",
                        "    out\n",
                        "    string\t\"result.txt\"\n",
                        "  param\n",
                        "    chunkSize\n",
                        "    int\t100\n",
                        "  process\n",
                        "    foo\n",
                        "    process_block\n",
                        "      directive\n",
                        "        container\n",
                        "          string\t'python'\n",
                        "      output\n",
                        "        path\n",
                        "          declaration\t'sample.txt'\n",
                        "      shell\n",
                        "        shell_script\t'''\n",
                        "    echo 'hello' >  sample.txt\n",
                        "    '''\n",
                        "  workflow\n",
                        "    workflow_block\n",
                        "      main\n",
                        "        function_call\tfoo()\n",
                        "        channel\n",
                        "          Channel\n",
                        "        .fromPath(params.query)\n",
                        "          split_fasta\t.splitFasta(by: params.chunkSize, file:true)\n",
                        "        .collectFile(name: params.out)\n",
                        "      comment\t//.set{ ch_fasta }\n",
                        "\n"
                    ]
                }
            ],
            "source": [
                "## # https://chat.openai.com/share/fb9d0650-3f66-4104-bff3-8697d5aeaf2e\n",
                "\n",
                "from pathlib import Path\n",
                "from lark import Lark\n",
                "\n",
                "test_file = test_1 \n",
                "#test_file = test_2Channel\\.(fromList|fromPath|fromFilePairs|fromSRA|from|of|empty|value|watchPath)\\(((\\S+)(\\s+)?,?)?\\) \n",
                "#nextflow_grammar = Path(\"../nf_parser/grammer/nf.lark\").read_text()\n",
                "nextflow_grammar = Path(\"./grammers/nf.lark\").read_text()\n",
                "parser = Lark(nextflow_grammar, parser='lalr')\n",
                "tree = parser.parse(test_file)\n",
                "print(tree)\n",
                "print(tree.pretty())"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
